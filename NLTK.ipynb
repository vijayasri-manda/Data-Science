{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnpZ7VdtyWYv5QgU7jy/6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijayasri-manda/Data-Science/blob/main/NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK:**Natural Lanaguage Tool Kit\n",
        "# Applications of NLP\n",
        "* spell Checking\n",
        "* keyword Search\n",
        "* Information Extraction\n",
        "* Advertisement Matching\n",
        "* Sentimental Analysis\n",
        "* Speech Recognition\n",
        "* Machine Translation"
      ],
      "metadata": {
        "id": "dPmZzRmckprs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByXrNwwreOON",
        "outputId": "d5e129e2-758b-45b5-aac8-c2b61863c616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stopwords** means commonly used words"
      ],
      "metadata": {
        "id": "bLngiRL_oTZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_stopwords=nltk.corpus.stopwords.words('english')\n",
        "nltk_stopwords"
      ],
      "metadata": {
        "id": "xkI63leMebjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26cb848-d96c-406f-cb91-1884a9f48578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\"]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"List of stop words in english:\\n%s\"%list(nltk_stopwords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XWIsj-ceiso",
        "outputId": "8b362f82-71df-46c6-e50e-16716b7c76de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of stop words in english:\n",
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of stop words\",len(nltk_stopwords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqEOdq3wev-l",
        "outputId": "9d79739b-c2a0-48bf-b856-1ea6cc8e454a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of stop words 198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUqOEEyZfZWz",
        "outputId": "575194ee-9bfb-48da-9083-4be002f52898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['albanian', 'arabic', 'azerbaijani', 'basque', 'belarusian', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'tamil', 'turkish']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords.words('spanish'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYcu-dT9fHZX",
        "outputId": "50efecec-9fa0-4bbd-a554-d2ff2d5b2542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"A wrapper around a sequence of simple (string) tokens, which is intended to support initial exploration of texts (via the interactive console).\n",
        "Its methods perform a variety of analyses on the text’s contexts (e.g., counting, concordancing, collocation discovery), and display the results. If you wish to write a program which makes use of these analyses, then you should bypass the Text class, and use the appropriate analysis function or class directly instead.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Q7UFupYwfXZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNIU-KbTgUDx",
        "outputId": "6e6cb28a-0648-42e1-bbe7-2d27e13cd86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n",
        "\n",
        "\n",
        "*   Break a Complex sentence into words\n",
        "*   Understand the importance of each words with respect to the sentence\n",
        "*  Produce a structural description on an input sentence\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YEmwTBxbsunI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Tokenization**\n",
        "# word_tokenize():\n",
        "This method used to break the given text into words."
      ],
      "metadata": {
        "id": "osiFu5qlzG8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_NLTK=nltk.word_tokenize(text)"
      ],
      "metadata": {
        "id": "FnPPn1iVgAYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_NLTK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB1m10eDgSSo",
        "outputId": "9236c237-574a-4cb3-9a98-8bcdb9428e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'wrapper',\n",
              " 'around',\n",
              " 'a',\n",
              " 'sequence',\n",
              " 'of',\n",
              " 'simple',\n",
              " '(',\n",
              " 'string',\n",
              " ')',\n",
              " 'tokens',\n",
              " ',',\n",
              " 'which',\n",
              " 'is',\n",
              " 'intended',\n",
              " 'to',\n",
              " 'support',\n",
              " 'initial',\n",
              " 'exploration',\n",
              " 'of',\n",
              " 'texts',\n",
              " '(',\n",
              " 'via',\n",
              " 'the',\n",
              " 'interactive',\n",
              " 'console',\n",
              " ')',\n",
              " '.',\n",
              " 'Its',\n",
              " 'methods',\n",
              " 'perform',\n",
              " 'a',\n",
              " 'variety',\n",
              " 'of',\n",
              " 'analyses',\n",
              " 'on',\n",
              " 'the',\n",
              " 'text',\n",
              " '’',\n",
              " 's',\n",
              " 'contexts',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'counting',\n",
              " ',',\n",
              " 'concordancing',\n",
              " ',',\n",
              " 'collocation',\n",
              " 'discovery',\n",
              " ')',\n",
              " ',',\n",
              " 'and',\n",
              " 'display',\n",
              " 'the',\n",
              " 'results',\n",
              " '.',\n",
              " 'If',\n",
              " 'you',\n",
              " 'wish',\n",
              " 'to',\n",
              " 'write',\n",
              " 'a',\n",
              " 'program',\n",
              " 'which',\n",
              " 'makes',\n",
              " 'use',\n",
              " 'of',\n",
              " 'these',\n",
              " 'analyses',\n",
              " ',',\n",
              " 'then',\n",
              " 'you',\n",
              " 'should',\n",
              " 'bypass',\n",
              " 'the',\n",
              " 'Text',\n",
              " 'class',\n",
              " ',',\n",
              " 'and',\n",
              " 'use',\n",
              " 'the',\n",
              " 'appropriate',\n",
              " 'analysis',\n",
              " 'function',\n",
              " 'or',\n",
              " 'class',\n",
              " 'directly',\n",
              " 'instead',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens_NLTK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo9xCp4ug4R8",
        "outputId": "512976d1-90fa-4572-a2d3-d305093803d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentence Tokenization**\n",
        "# sent_tokenize():\n",
        "This method used to break the given text into sentences"
      ],
      "metadata": {
        "id": "cgcf5YHXy2G_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_NLTK=nltk.sent_tokenize(text)\n",
        "sentences_NLTK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p4CxH52ydmg",
        "outputId": "845e6c79-6d43-4087-fdaf-f8cc9f714e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A wrapper around a sequence of simple (string) tokens, which is intended to support initial exploration of texts (via the interactive console).',\n",
              " 'Its methods perform a variety of analyses on the text’s contexts (e.g., counting, concordancing, collocation discovery), and display the results.',\n",
              " 'If you wish to write a program which makes use of these analyses, then you should bypass the Text class, and use the appropriate analysis function or class directly instead.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences_NLTK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubWdPPimzTwf",
        "outputId": "866d7365-611b-4735-b234-65e8b45089ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove Stopwords\n",
        "filtered_tokens_NLTK=[word for word in tokens_NLTK if word.lower() not in stopwords.words('english')]\n",
        "print(\"Original TOkens:\",tokens_NLTK)\n",
        "print(\"Filtered Tokens:\",filtered_tokens_NLTK)\n",
        "print(\"old text length:\",len(tokens_NLTK))\n",
        "print(\"new text length:\",len(filtered_tokens_NLTK))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LUmI9-fhO5o",
        "outputId": "e155bd8e-2b2e-4bc4-ffa3-98178ee3ed18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original TOkens: ['A', 'wrapper', 'around', 'a', 'sequence', 'of', 'simple', '(', 'string', ')', 'tokens', ',', 'which', 'is', 'intended', 'to', 'support', 'initial', 'exploration', 'of', 'texts', '(', 'via', 'the', 'interactive', 'console', ')', '.', 'Its', 'methods', 'perform', 'a', 'variety', 'of', 'analyses', 'on', 'the', 'text', '’', 's', 'contexts', '(', 'e.g.', ',', 'counting', ',', 'concordancing', ',', 'collocation', 'discovery', ')', ',', 'and', 'display', 'the', 'results', '.', 'If', 'you', 'wish', 'to', 'write', 'a', 'program', 'which', 'makes', 'use', 'of', 'these', 'analyses', ',', 'then', 'you', 'should', 'bypass', 'the', 'Text', 'class', ',', 'and', 'use', 'the', 'appropriate', 'analysis', 'function', 'or', 'class', 'directly', 'instead', '.']\n",
            "Filtered Tokens: ['wrapper', 'around', 'sequence', 'simple', '(', 'string', ')', 'tokens', ',', 'intended', 'support', 'initial', 'exploration', 'texts', '(', 'via', 'interactive', 'console', ')', '.', 'methods', 'perform', 'variety', 'analyses', 'text', '’', 'contexts', '(', 'e.g.', ',', 'counting', ',', 'concordancing', ',', 'collocation', 'discovery', ')', ',', 'display', 'results', '.', 'wish', 'write', 'program', 'makes', 'use', 'analyses', ',', 'bypass', 'Text', 'class', ',', 'use', 'appropriate', 'analysis', 'function', 'class', 'directly', 'instead', '.']\n",
            "old text length: 90\n",
            "new text length: 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s=stopwords.words('tamil')\n",
        "print(list(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpwbJ1mB0Isd",
        "outputId": "5d7c0d86-597d-4a5e-93a5-2dfa434c0b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['அங்கு', 'அங்கே', 'அடுத்த', 'அதனால்', 'அதன்', 'அதற்கு', 'அதிக', 'அதில்', 'அது', 'அதே', 'அதை', 'அந்த', 'அந்தக்', 'அந்தப்', 'அன்று', 'அல்லது', 'அவன்', 'அவரது', 'அவர்', 'அவர்கள்', 'அவள்', 'அவை', 'ஆகிய', 'ஆகியோர்', 'ஆகும்', 'இங்கு', 'இங்கே', 'இடத்தில்', 'இடம்', 'இதனால்', 'இதனை', 'இதன்', 'இதற்கு', 'இதில்', 'இது', 'இதை', 'இந்த', 'இந்தக்', 'இந்தத்', 'இந்தப்', 'இன்னும்', 'இப்போது', 'இரு', 'இருக்கும்', 'இருந்த', 'இருந்தது', 'இருந்து', 'இவர்', 'இவை', 'உன்', 'உள்ள', 'உள்ளது', 'உள்ளன', 'எந்த', 'என', 'எனக்', 'எனக்கு', 'எனப்படும்', 'எனவும்', 'எனவே', 'எனினும்', 'எனும்', 'என்', 'என்ன', 'என்னும்', 'என்பது', 'என்பதை', 'என்ற', 'என்று', 'என்றும்', 'எல்லாம்', 'ஏன்', 'ஒரு', 'ஒரே', 'ஓர்', 'கொண்ட', 'கொண்டு', 'கொள்ள', 'சற்று', 'சிறு', 'சில', 'சேர்ந்த', 'தனது', 'தன்', 'தவிர', 'தான்', 'நான்', 'நாம்', 'நீ', 'பற்றி', 'பற்றிய', 'பல', 'பலரும்', 'பல்வேறு', 'பின்', 'பின்னர்', 'பிற', 'பிறகு', 'பெரும்', 'பேர்', 'போது', 'போன்ற', 'போல', 'போல்', 'மட்டுமே', 'மட்டும்', 'மற்ற', 'மற்றும்', 'மிக', 'மிகவும்', 'மீது', 'முதல்', 'முறை', 'மேலும்', 'மேல்', 'யார்', 'வந்த', 'வந்து', 'வரும்', 'வரை', 'வரையில்', 'விட', 'விட்டு', 'வேண்டும்', 'வேறு']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s=stopwords.words('german')\n",
        "print(list(s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_5l7Zae0Vt8",
        "outputId": "623e6c3d-2bd0-4950-8383-9cfd0780d423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aber', 'alle', 'allem', 'allen', 'aller', 'alles', 'als', 'also', 'am', 'an', 'ander', 'andere', 'anderem', 'anderen', 'anderer', 'anderes', 'anderm', 'andern', 'anderr', 'anders', 'auch', 'auf', 'aus', 'bei', 'bin', 'bis', 'bist', 'da', 'damit', 'dann', 'der', 'den', 'des', 'dem', 'die', 'das', 'dass', 'daß', 'derselbe', 'derselben', 'denselben', 'desselben', 'demselben', 'dieselbe', 'dieselben', 'dasselbe', 'dazu', 'dein', 'deine', 'deinem', 'deinen', 'deiner', 'deines', 'denn', 'derer', 'dessen', 'dich', 'dir', 'du', 'dies', 'diese', 'diesem', 'diesen', 'dieser', 'dieses', 'doch', 'dort', 'durch', 'ein', 'eine', 'einem', 'einen', 'einer', 'eines', 'einig', 'einige', 'einigem', 'einigen', 'einiger', 'einiges', 'einmal', 'er', 'ihn', 'ihm', 'es', 'etwas', 'euer', 'eure', 'eurem', 'euren', 'eurer', 'eures', 'für', 'gegen', 'gewesen', 'hab', 'habe', 'haben', 'hat', 'hatte', 'hatten', 'hier', 'hin', 'hinter', 'ich', 'mich', 'mir', 'ihr', 'ihre', 'ihrem', 'ihren', 'ihrer', 'ihres', 'euch', 'im', 'in', 'indem', 'ins', 'ist', 'jede', 'jedem', 'jeden', 'jeder', 'jedes', 'jene', 'jenem', 'jenen', 'jener', 'jenes', 'jetzt', 'kann', 'kein', 'keine', 'keinem', 'keinen', 'keiner', 'keines', 'können', 'könnte', 'machen', 'man', 'manche', 'manchem', 'manchen', 'mancher', 'manches', 'mein', 'meine', 'meinem', 'meinen', 'meiner', 'meines', 'mit', 'muss', 'musste', 'nach', 'nicht', 'nichts', 'noch', 'nun', 'nur', 'ob', 'oder', 'ohne', 'sehr', 'sein', 'seine', 'seinem', 'seinen', 'seiner', 'seines', 'selbst', 'sich', 'sie', 'ihnen', 'sind', 'so', 'solche', 'solchem', 'solchen', 'solcher', 'solches', 'soll', 'sollte', 'sondern', 'sonst', 'über', 'um', 'und', 'uns', 'unsere', 'unserem', 'unseren', 'unser', 'unseres', 'unter', 'viel', 'vom', 'von', 'vor', 'während', 'war', 'waren', 'warst', 'was', 'weg', 'weil', 'weiter', 'welche', 'welchem', 'welchen', 'welcher', 'welches', 'wenn', 'werde', 'werden', 'wie', 'wieder', 'will', 'wir', 'wird', 'wirst', 'wo', 'wollen', 'wollte', 'würde', 'würden', 'zu', 'zum', 'zur', 'zwar', 'zwischen']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "Stemming generates the base word from the inflected word by removing the affixes of the word."
      ],
      "metadata": {
        "id": "E1Z5qsmi0oey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# create an object of class PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "print(porter.stem(\"play\"))\n",
        "print(porter.stem(\"playing\"))\n",
        "print(porter.stem(\"plays\"))\n",
        "print(porter.stem(\"played\"))"
      ],
      "metadata": {
        "id": "9TPNSkbe0pvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "# create an object of class PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "print(porter.stem(\"Communication\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMg8QQ5oC4oa",
        "outputId": "793fea6c-981e-4a2e-ad79-10c4ca60c65c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "commun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "# create an object of class PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "print(porter.stem(\"vijayasrireddy\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgv7Z0kFC6yi",
        "outputId": "a3ec8f7c-a9e0-4a95-ba94-67b866e7d07b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vijayasrireddi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization\n",
        "Lemmatization involves grouping together the inflected forms of the same word. This way, we can reach out to the base form of any word which will be meaningful in nature. The base from here is called the Lemma.\n",
        "\n"
      ],
      "metadata": {
        "id": "PV2DIuygDIO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "# Download the 'wordnet' corpus\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zveKmEIrEWoU",
        "outputId": "c332fe3e-0707-4172-b6a1-0395b4af7f62"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# create an object of class WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(lemmatizer.lemmatize(\"plays\", 'v'))\n",
        "print(lemmatizer.lemmatize(\"played\", 'v'))\n",
        "print(lemmatizer.lemmatize(\"play\", 'v'))\n",
        "print(lemmatizer.lemmatize(\"playing\", 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s77_bJ5iEyLO",
        "outputId": "96c7df31-1e3b-4a61-87fd-2d855e54f7ff"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "play\n",
            "play\n",
            "play\n",
            "play\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# create an object of class WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(lemmatizer.lemmatize(\"Communication\", 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtKeCJyyE9-1",
        "outputId": "bf14242e-e20c-4411-ed7d-35f72cb935a5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Communication\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# create an object of class WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(lemmatizer.lemmatize(\"vijayasrireddy\", 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXmFPjURFEYk",
        "outputId": "bd77028f-9b85-4a41-cb46-0753029ecff7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vijayasrireddy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy_nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "sGE1PtZuhh9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spacy_nlp=spacy.lang.en.stop_words.STOP_WORDS\n",
        "print(\"List of stop words in english:\\n%s\"%list(spacy_nlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUUV4xi2kN1X",
        "outputId": "1ae53af9-b88f-4293-f95c-3c56606f3952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of stop words in english:\n",
            "['forty', 'two', 'becomes', 'some', 'cannot', 'were', 'whenever', 'else', 'without', 'within', \"'re\", 'among', 'using', 'as', 'will', 'wherein', 'mostly', 'former', 'already', 'yourselves', 'our', '‘m', 'it', 'formerly', 'him', 'quite', 'both', 'that', 'nine', 'now', 'another', 'anything', 'fifty', 'might', 'hereupon', 'whom', 'thence', 'please', 'much', 'however', 'mine', 'over', '‘s', 'are', 'for', 'such', '’s', 'noone', 'she', 'yet', 'either', 'and', 'of', 'do', 'elsewhere', 'everyone', 'although', 'further', 'could', 'go', 'those', 'be', 'he', 'below', 'make', 'throughout', 'into', 'due', 'these', 'through', 'along', 'her', 'hers', 'herself', 'than', 'nevertheless', 'often', 'every', 'seeming', 'last', 'whereupon', 'i', 'various', 'about', 'toward', 'almost', 'himself', 'only', 'thru', 'down', 'nobody', 'then', 'put', 'itself', 'we', 'three', 'always', 'meanwhile', 'alone', \"'m\", '‘d', 'therein', 'latter', 'once', 'whoever', 'nothing', 'to', 're', 'whether', 'via', 'each', 'least', 'ours', 'them', 'is', 'the', 'serious', 'whence', 'though', 'eight', 'anyone', 'twelve', 'yourself', \"n't\", 'herein', 'get', 'most', 'somewhere', 'less', 'rather', 'would', 'move', 'never', 'thereby', 'six', 'so', 'thereupon', 'under', 'very', 'others', 'doing', 'empty', 'their', 'you', 'made', \"'ve\", 'used', 'take', 'hundred', 'above', 'they', 'must', 'too', 'themselves', \"'d\", 'an', 'before', 'myself', 'moreover', 'while', 'or', '‘ll', 'us', '’d', 'until', 'how', \"'ll\", '’re', 'beyond', 'on', 'in', 'full', 'just', 'by', '‘re', 'thus', 'against', 'sometime', \"'s\", 'was', 'ca', 'seem', 'first', 'side', '’m', 'a', 'everything', 'between', 'ten', 'this', 'something', 'several', 'really', 'because', 'from', 'your', 'again', 'ever', 'see', 'there', 'indeed', 'his', 'keep', 'front', 'per', 'may', 'whole', 'fifteen', 'who', '‘ve', 'out', 'regarding', 'twenty', 'sometimes', 'enough', 'whither', 'not', 'seemed', 'anyway', 'give', 'four', 'should', 'wherever', 'if', 'anywhere', 'own', 'am', 'even', 'being', 'does', 'any', 'ourselves', 'together', 'yours', 'top', 'has', 'hence', 'few', 'say', 'five', 'show', 'back', 'also', 'did', 'everywhere', 'during', 'what', 'someone', 'other', 'since', 'when', 'across', 'can', 'up', 'namely', 'call', 'latterly', 'except', 'nowhere', 'eleven', 'have', 'none', 'whose', 'neither', 'amount', 'here', 'why', 'where', 'thereafter', 'anyhow', 'becoming', 'still', 'nor', 'therefore', 'onto', 'my', 'its', 'with', 'off', 'amongst', 'n’t', 'me', 'next', 'at', 'otherwise', 'towards', 'perhaps', 'upon', 'hereby', 'all', 'become', 'afterwards', 'name', 'whereas', 'more', 'beforehand', 'third', 'one', 'many', 'well', 'been', '’ve', 'which', 'behind', 'became', 'part', 'around', 'whereby', 'done', 'n‘t', 'no', 'beside', '’ll', 'whereafter', 'somehow', 'besides', 'unless', 'hereafter', 'same', 'had', 'bottom', 'but', 'whatever', 'after', 'sixty', 'seems']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#length of stopwords\n",
        "print(\"length of stop words\",len(spacy_nlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsYtSUDPjGDs",
        "outputId": "ab974163-5cbb-4229-d466-a3ac2eb5b8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of stop words 326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization\n",
        "import spacy\n",
        "spacy_model = spacy.load('en_core_web_sm')\n",
        "\n",
        "tokens_spacy = [token.text for token in spacy_model(text)]\n",
        "print(tokens_spacy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHmgKNEejVlx",
        "outputId": "e1ac68c4-3363-46f7-c83d-116ee1a68234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'wrapper', 'around', 'a', 'sequence', 'of', 'simple', '(', 'string', ')', 'tokens', ',', 'which', 'is', 'intended', 'to', 'support', 'initial', 'exploration', 'of', 'texts', '(', 'via', 'the', 'interactive', 'console', ')', '.', '\\n', 'Its', 'methods', 'perform', 'a', 'variety', 'of', 'analyses', 'on', 'the', 'text', '’s', 'contexts', '(', 'e.g.', ',', 'counting', ',', 'concordancing', ',', 'collocation', 'discovery', ')', ',', 'and', 'display', 'the', 'results', '.', 'If', 'you', 'wish', 'to', 'write', 'a', 'program', 'which', 'makes', 'use', 'of', 'these', 'analyses', ',', 'then', 'you', 'should', 'bypass', 'the', 'Text', 'class', ',', 'and', 'use', 'the', 'appropriate', 'analysis', 'function', 'or', 'class', 'directly', 'instead', '.', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens_spacy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8fI2qOJj4kc",
        "outputId": "40b0e066-a822-4664-de0b-f51bb3d2b5e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens_spacy=[word for word in tokens_spacy if word.lower() not in spacy_nlp]\n",
        "print(\"Original TOkens:\",tokens_spacy)\n",
        "print(\"Filtered Tokens:\",filtered_tokens_spacy)\n",
        "print(\"old text length:\",len(tokens_spacy))\n",
        "print(\"new text length:\",len(filtered_tokens_spacy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h59rs2zEkYpz",
        "outputId": "bc192b07-b54d-4130-bc8b-94d5c3b00974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original TOkens: ['A', 'wrapper', 'around', 'a', 'sequence', 'of', 'simple', '(', 'string', ')', 'tokens', ',', 'which', 'is', 'intended', 'to', 'support', 'initial', 'exploration', 'of', 'texts', '(', 'via', 'the', 'interactive', 'console', ')', '.', '\\n', 'Its', 'methods', 'perform', 'a', 'variety', 'of', 'analyses', 'on', 'the', 'text', '’s', 'contexts', '(', 'e.g.', ',', 'counting', ',', 'concordancing', ',', 'collocation', 'discovery', ')', ',', 'and', 'display', 'the', 'results', '.', 'If', 'you', 'wish', 'to', 'write', 'a', 'program', 'which', 'makes', 'use', 'of', 'these', 'analyses', ',', 'then', 'you', 'should', 'bypass', 'the', 'Text', 'class', ',', 'and', 'use', 'the', 'appropriate', 'analysis', 'function', 'or', 'class', 'directly', 'instead', '.', '\\n']\n",
            "Filtered Tokens: ['wrapper', 'sequence', 'simple', '(', 'string', ')', 'tokens', ',', 'intended', 'support', 'initial', 'exploration', 'texts', '(', 'interactive', 'console', ')', '.', '\\n', 'methods', 'perform', 'variety', 'analyses', 'text', 'contexts', '(', 'e.g.', ',', 'counting', ',', 'concordancing', ',', 'collocation', 'discovery', ')', ',', 'display', 'results', '.', 'wish', 'write', 'program', 'makes', 'use', 'analyses', ',', 'bypass', 'Text', 'class', ',', 'use', 'appropriate', 'analysis', 'function', 'class', 'directly', 'instead', '.', '\\n']\n",
            "old text length: 91\n",
            "new text length: 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens_spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9FLV5frkfs-",
        "outputId": "bf238a95-f6f4-499d-e003-b4b7fe457700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wrapper',\n",
              " 'sequence',\n",
              " 'simple',\n",
              " '(',\n",
              " 'string',\n",
              " ')',\n",
              " 'tokens',\n",
              " ',',\n",
              " 'intended',\n",
              " 'support',\n",
              " 'initial',\n",
              " 'exploration',\n",
              " 'texts',\n",
              " '(',\n",
              " 'interactive',\n",
              " 'console',\n",
              " ')',\n",
              " '.',\n",
              " '\\n',\n",
              " 'methods',\n",
              " 'perform',\n",
              " 'variety',\n",
              " 'analyses',\n",
              " 'text',\n",
              " 'contexts',\n",
              " '(',\n",
              " 'e.g.',\n",
              " ',',\n",
              " 'counting',\n",
              " ',',\n",
              " 'concordancing',\n",
              " ',',\n",
              " 'collocation',\n",
              " 'discovery',\n",
              " ')',\n",
              " ',',\n",
              " 'display',\n",
              " 'results',\n",
              " '.',\n",
              " 'wish',\n",
              " 'write',\n",
              " 'program',\n",
              " 'makes',\n",
              " 'use',\n",
              " 'analyses',\n",
              " ',',\n",
              " 'bypass',\n",
              " 'Text',\n",
              " 'class',\n",
              " ',',\n",
              " 'use',\n",
              " 'appropriate',\n",
              " 'analysis',\n",
              " 'function',\n",
              " 'class',\n",
              " 'directly',\n",
              " 'instead',\n",
              " '.',\n",
              " '\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"existing length of the stopwords in nltk library:\",len(nltk_stopwords))\n",
        "print(\"existing length of the stopwords in spacy library:\",len(spacy_nlp))"
      ],
      "metadata": {
        "id": "4sgkYVVGm6u0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3e8836-3f31-445d-b7eb-31b50f2cd90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "existing length of the stopwords in nltk library: 198\n",
            "existing length of the stopwords in spacy library: 326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_stopwords.append('example1')\n",
        "len(nltk_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD4uynuHK1oS",
        "outputId": "a311f083-02b5-454b-ec9f-e92606fe2cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_stopwords.extend(['example2','example3'])\n",
        "len(nltk_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_0BL2JhLENr",
        "outputId": "2e310318-d5c7-4478-8f1e-4c5fffc0cc6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUKnMSEALJPa",
        "outputId": "a242acff-225b-41e1-8a1c-fa7158e2dc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\",\n",
              " 'example1',\n",
              " 'example2',\n",
              " 'example3']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_stopwords.remove('example1')\n",
        "len(nltk_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjVKtmmuLOz5",
        "outputId": "a25b3771-8ec0-4867-eb49-ea2d56276195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T0mPXk5LSol",
        "outputId": "a2a48bdd-713c-4eed-e72a-86efd88ff9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " \"he's\",\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " 'if',\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " \"i've\",\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " \"should've\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " \"we've\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " 'your',\n",
              " \"you're\",\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " \"you've\",\n",
              " 'example2',\n",
              " 'example3']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Difference between NLTK and Spacy\n",
        "**NLTK**\n",
        "* NLTK is mainly a string processing library.\n",
        "\n",
        "* Provides access to many algorithms.If you care about specific algorithms and customizations go with NLTK.\n",
        "* NLTK is old library.User community as active as Spacy.\n",
        "* 198 Stopwords.\n",
        "\n",
        "\n",
        "**SPACY**\n",
        "* Spacy is Object oriented.\n",
        "* Provides most efficient NLP algortihm for a given task.Hence if you care about the end result,go with Spacy.\n",
        "* Spacy is new library and has a very active user community.\n",
        "* 326 Stopwords."
      ],
      "metadata": {
        "id": "GKNABBZ0FA-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "K-O1tfT-Nieh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Vijaya sri Manda from Seshadri Rao gudlavalleru Engineering College.Currently pursuing 3rd year btech in Artificial Intelligence and Data science\")\n",
        "for sentence in doc.sents:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltN1qJJ6FEs3",
        "outputId": "94d574f2-6fb5-43f3-e982-a7336a786d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vijaya sri Manda from Seshadri Rao gudlavalleru Engineering College.\n",
            "Currently pursuing 3rd year btech in Artificial Intelligence and Data science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in doc.sents:\n",
        "  for word in sentence:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR5FFojtFqSD",
        "outputId": "177d8a7c-d391-488d-f3c5-4f5b049c2e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vijaya\n",
            "sri\n",
            "Manda\n",
            "from\n",
            "Seshadri\n",
            "Rao\n",
            "gudlavalleru\n",
            "Engineering\n",
            "College\n",
            ".\n",
            "Currently\n",
            "pursuing\n",
            "3rd\n",
            "year\n",
            "btech\n",
            "in\n",
            "Artificial\n",
            "Intelligence\n",
            "and\n",
            "Data\n",
            "science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "B4OgPFI4F2XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(\"Vijaya sri Manda from Seshadri Rao gudlavalleru Engineering College.Currently pursuing 3rd year btech in Artificial Intelligence and Data science\")"
      ],
      "metadata": {
        "id": "ABydMsgRF-SA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4865c8-e7a4-4321-ab5f-b3a06adacdf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Vijaya sri Manda from Seshadri Rao gudlavalleru Engineering College.Currently pursuing 3rd year btech in Artificial Intelligence and Data science']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(\"Vijaya sri Manda from Seshadri Rao gudlavalleru Engineering College.Currently pursuing 3rd year btech in Artificial Intelligence and Data science\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR62E8XYGKPm",
        "outputId": "eb6dd8b0-6f65-4c49-c9ce-2841d3cadba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Vijaya',\n",
              " 'sri',\n",
              " 'Manda',\n",
              " 'from',\n",
              " 'Seshadri',\n",
              " 'Rao',\n",
              " 'gudlavalleru',\n",
              " 'Engineering',\n",
              " 'College.Currently',\n",
              " 'pursuing',\n",
              " '3rd',\n",
              " 'year',\n",
              " 'btech',\n",
              " 'in',\n",
              " 'Artificial',\n",
              " 'Intelligence',\n",
              " 'and',\n",
              " 'Data',\n",
              " 'science']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# customation of stopwords\n",
        "text='''The community of volunteers behind Wikipedia is the most important and unique element of Wikipedia’s success. For nearly 25 years, Wikipedia editors have researched, deliberated, discussed, built consensus, and collaboratively written the largest encyclopedia humankind has ever seen. Their care and commitment to reliable encyclopedic knowledge is something AI cannot replace.\n",
        "\n",
        "That is why our new AI strategy doubles down on the volunteers behind Wikipedia.\n",
        "\n",
        "We will use AI to build features that remove technical barriers to allow the humans at the core of Wikipedia to spend their valuable time on what they want to accomplish, and not on how to technically achieve it. Our investments will be focused on specific areas where generative AI excels, all in the service of creating unique opportunities that will boost Wikipedia’s volunteers:\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "C0PRXFFrGnrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_stopwords=['Wikipedia','AI','the','to','is']"
      ],
      "metadata": {
        "id": "J33Yosy6MJiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=nltk.word_tokenize(text)"
      ],
      "metadata": {
        "id": "Zq5PjnfbMZIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCklhOpvMtea",
        "outputId": "cb51f382-b51f-4d12-87bc-f543e9fb8511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'community', 'of', 'volunteers', 'behind', 'Wikipedia', 'is', 'the', 'most', 'important', 'and', 'unique', 'element', 'of', 'Wikipedia', '’', 's', 'success', '.', 'For', 'nearly', '25', 'years', ',', 'Wikipedia', 'editors', 'have', 'researched', ',', 'deliberated', ',', 'discussed', ',', 'built', 'consensus', ',', 'and', 'collaboratively', 'written', 'the', 'largest', 'encyclopedia', 'humankind', 'has', 'ever', 'seen', '.', 'Their', 'care', 'and', 'commitment', 'to', 'reliable', 'encyclopedic', 'knowledge', 'is', 'something', 'AI', 'can', 'not', 'replace', '.', 'That', 'is', 'why', 'our', 'new', 'AI', 'strategy', 'doubles', 'down', 'on', 'the', 'volunteers', 'behind', 'Wikipedia', '.', 'We', 'will', 'use', 'AI', 'to', 'build', 'features', 'that', 'remove', 'technical', 'barriers', 'to', 'allow', 'the', 'humans', 'at', 'the', 'core', 'of', 'Wikipedia', 'to', 'spend', 'their', 'valuable', 'time', 'on', 'what', 'they', 'want', 'to', 'accomplish', ',', 'and', 'not', 'on', 'how', 'to', 'technically', 'achieve', 'it', '.', 'Our', 'investments', 'will', 'be', 'focused', 'on', 'specific', 'areas', 'where', 'generative', 'AI', 'excels', ',', 'all', 'in', 'the', 'service', 'of', 'creating', 'unique', 'opportunities', 'that', 'will', 'boost', 'Wikipedia', '’', 's', 'volunteers', ':']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_tokens=[word for word in tokens if word.lower() not in custom_stopwords]\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liA6Fc_LMxnY",
        "outputId": "59f5d703-9eb5-4002-c34f-b8876e6d7f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['community', 'of', 'volunteers', 'behind', 'Wikipedia', 'most', 'important', 'and', 'unique', 'element', 'of', 'Wikipedia', '’', 's', 'success', '.', 'For', 'nearly', '25', 'years', ',', 'Wikipedia', 'editors', 'have', 'researched', ',', 'deliberated', ',', 'discussed', ',', 'built', 'consensus', ',', 'and', 'collaboratively', 'written', 'largest', 'encyclopedia', 'humankind', 'has', 'ever', 'seen', '.', 'Their', 'care', 'and', 'commitment', 'reliable', 'encyclopedic', 'knowledge', 'something', 'AI', 'can', 'not', 'replace', '.', 'That', 'why', 'our', 'new', 'AI', 'strategy', 'doubles', 'down', 'on', 'volunteers', 'behind', 'Wikipedia', '.', 'We', 'will', 'use', 'AI', 'build', 'features', 'that', 'remove', 'technical', 'barriers', 'allow', 'humans', 'at', 'core', 'of', 'Wikipedia', 'spend', 'their', 'valuable', 'time', 'on', 'what', 'they', 'want', 'accomplish', ',', 'and', 'not', 'on', 'how', 'technically', 'achieve', 'it', '.', 'Our', 'investments', 'will', 'be', 'focused', 'on', 'specific', 'areas', 'where', 'generative', 'AI', 'excels', ',', 'all', 'in', 'service', 'of', 'creating', 'unique', 'opportunities', 'that', 'will', 'boost', 'Wikipedia', '’', 's', 'volunteers', ':']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-aeQv-RNGez",
        "outputId": "ac2cc5ce-222d-4fc5-8ffd-50d6625fb9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "147"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMIkXJ5ZM759",
        "outputId": "589cdd00-1f46-4ded-efc0-64c68d7b269c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}